#+TITLE: Relationship of Model Parameters and Solution Stability in the Power Walk Page Rank Method.
:PREAMBLE:
# #+OPTIONS: broken-links:auto todo:nil H:9
#+OPTIONS: broken-links:auto H:9
#+OPTIONS: broken-links:auto
#+INFOJS_OPT: view:showall toc:3
#+PLOT: title:"Citas" ind:1 deps:(3) type:2d with:histograms set:"yrange [0:]"
#+OPTIONS: tex:t
#+TODO: TODO IN-PROGRESS WAITING DONE
#+CATEGORY: DProj
:END:
:HTML:
#+INFOJS_OPT: view:info toc:3
#+HTML_HEAD_EXTRA: <link rel="stylesheet" type="text/css" href="../resources/style.css">
#+CSL_STYLE: ../resources/nature.csl
:END:
:R:
#+PROPERTY: header-args:R :session TADMain :dir ./ :cache yes :eval :exports both
#+PROPERTY: header-args :eval never-export
:END:
:LATEX:
#+LATEX_HEADER: \IfFileExists{../resources/style.sty}{\usepackage{../resources/style}}{}
#+LATEX_HEADER: \IfFileExists{../resources/referencing.sty}{\usepackage{../resources/referencing}}{}
#+LATEX_HEADER: \addbibresource{../resources/references.bib}
:END:
* Introduction

Much information is interconnected, be it an article, research paper, movie,
books, personal notes, knowledge bases, peronal releationships etc., this
interconnectivity creates a network which can naturally visualised as a graph.

Determining which vertex of such a graph is most central is useful as it may
assist in research, learning and collaborating. The /Page Rank/ method, which
originally underpinned [[www.google.com][Google]]'s search-engine, essentially asserts that the
centre most vertex of a graph could be considered the vertex that has the
highest probability of being a destination following a random walk
cite:larrypageAnatomyLargescaleHypertextual1998, although this method is
popular, it does not however, easily adapt to negatively weighted edges (a
negative weight in this case measuring dissaproval or an aversion to follow that
link, like an advertisement, as opposed to endorsement). A limitation which is
increasingly important as the area of /Sentiment Analysis/ within the field of
/Text Mining/ is developed. cite:parkPowerWalkProceedings2013

The /Power Walk/ Method is similar to the /Random Surfer/ model but takes a
different approach in order to accomadate the potential for an edge to have any
arbirary real weight. cite:parkPowerWalkProceedings2013

This research project will be an investigation into the relationship between
model parameters and the solution stability of the /Power Walk/ method.

** Motivation

Taking advantages of inter-related ideas allows for exploratory research which
can promote both a deeper and broader understading of a topic, an example of
this is the concept of a /pathfinder/, which is a list of central sources for a
topic that can help in early stages of literature searches,
cite:harbesonTeachingReferenceBibliography1972
Examples of such Pathfinders include:

- Institution examples:
  + [[https://libraries.mit.edu/experts/][/M.I.T./]] cite:mitResearchGuidesExpert
  + [[https://guides.library.harvard.edu/][/Harvard/]] cite:harvarduniversityResearchGuides
  + [[https://www.lib.berkeley.edu/libraries/business-library][Berkley University]] cite:berkleyuniversityBusinessLibraryUC
  + [[https://www.loc.gov/rr/scitech/tracer-bullets/][/Library of Congress/]] cite:ScienceTracerBullets
    - The Library of Congress refers to a /PathFinder/ as a /Tracer Bullet/, which is both a very descriptive and very American name.
- Wiki Examples:
  + [[http://mathonline.wikidot.com/][Math Online]]  cite:Mathonline
  + [[https://brilliant.org/wiki/best/][Top /Brilliant/ Wiki Pages]] cite:Top100Wiki
  + [[https://www.mediawiki.org/wiki/Help:Categories][Category Pages within MediaWiki Sites]] cite:HelpCategoriesMediaWiki
    + For example the [[https://en.wikipedia.org/wiki/Category:Mathematics][Mathematics Category Page]] cite:CategoryMathematics2019

Using /Wikipedia/ for example can make for a very effective subject guide by
following the various hyperlinks across wikipedia and leveraging [[https://www.mediawiki.org/wiki/Help:Categories][Category Pages]]
cite:HelpCategoriesMediaWiki in order to map out a topic while referring to
references as necessary. Such a strategy even recommended by some [[https://mville.libguides.com/c.php?g=370066&p=2500344][Library Study
Guides]] cite:moskowitzLibraryGuidesWikipedia, and has even been
implemented in recommendation systems to overcome a lack of data
cite:loizouUsingWikipediaAlleviate2010a (see section of litreview? [[#wiki-networks]]).

Similarly the [[https://en.wikipedia.org/wiki/Collective_Knowledge_(software)][/Zettelkasten/ method]] of note taking essentially involves a collection of
small interlinked notes cite:OverviewZettelkastenMethod, much like a wiki,
within the last two decades this method has peaked in popularity
cite:GoogleBooksNgram, despite being a method dating back to atleast the 18th
Century. cite:haarkoetterAllesWesentlicheFindet This is clearly driven in party
by the development of the internet, /HTML/ and the increasing breadth and depth
of human knowledge.

A comprehensive review of the pathfinder approach, however, reveals that many
such subject guides are not consistent with the needs of those engaging in
research on any given topic. cite:vilenoPaperElectronicEvolution2007 This
issue is somewhat analogous to the issue faced by Larry Page and Sergey Brin in
that the centrality of an article of information corresponds very greatly to
it's relevance. cite:larrypageAnatomyLargescaleHypertextual1998

* Background and Rationale
** Background of issue
Given some graph $G(V,E)$ with $\mid V \mid = n$, a corresponding adjacency
matrix $\mathbf{A}$ describes the number of edges between vertex $i$ and $j$,
such that $\mathbf{A}_{i, j}$ represents the number of edges between the
vertices, with respect to a directed graph the entry may either denote:

- $i \rightarrow j$
  - One such example of this implementation being the ~igraph~ library cite:gaborcsardiIgraphManualPages2019
- $j \rightarrow i$ [[cite:nicholsonLinearAlgebraApplications2009][\textsection 2.3]]

While both definitions appear in the literature, the latter definition is more
common/convenient when working with /probability transition matrices/ and will
hence be adopted here.

*** Stationary Distribution
:PROPERTIES:
:CUSTOM_ID: stationary-distribution
:END:
Given this adjacency matrix $\mathbf{A}$, in order to have each element
$\mathrm{A}_{i, j}$ represent the probability of leaving $j$ and travelling to
$i$ during a random walk (as opposed to the number of edges), each column will
need to be scaled to one, this can be acheived with matrix multiplication as
illustrated in eqref:eq:mat-mult-colsum:

\begin{align}
\mathbf{T} = \mathbf{A} \enspace \mathrm{diag}\left( \mathtt{colsums}\left(
\mathbf{A} \right) \right) \label{eq:mat-mult-colsum} \end{align}

The state distribution $\vec{p}_{k}$ describes the probability of visiting each
vertex during a random walk for the $k^{\textrm{th}}$ step of the walk, given
this, the stationary distribution $\vec{p}$ is given by
eqref:eq:stationary-distribution:


\begin{align}
\vec{p_{i}} &= \mathbf{T} p_{i-1} \nonumber \\ \lim_{n \to \infty} \left[
\vec{p_{i}} \right] &= \lim_{n \to \infty} \left[ \mathbf{T} \vec{p_{i-1}}
\right] \nonumber \\ \implies \vec{p} &= \mathbf{T} \vec{p}
\label{eq:stationary-distribution} \end{align}

If $G(V, E)$ is an ergodic graph (i.e. all vertices may be reached from any
initial vertex), this can be solved by iteration by setting some threshold
$(\eta)$ for convergence (which will be referred to as the /Power Method/) or by
solving the eigenvalue problem for $\lambda=1$ as shown in eqref:eq:eigen-one:

\begin{align}
\lambda \vec{p} &= \mathbf{T} \vec{p} \nonumber \\ \lambda = 1 \implies \vec{p}
&= \mathbf{T} \vec{p} \label{eq:eigen-one} \end{align}

** Random Surfer
If however a graph is non-ergodic, this random walk will not traverse every
vertex, to overcome this, the /Random Surfer/ model can be implemented
cite:larrypageAnatomyLargescaleHypertextual1998, by essentially introducing,
into the /probability transition matrix/ $(\mathbf{T})$, some probability
$(\frac{1-\alpha}{n})$ of traversing to a disconnected vertex $(V)$, this is
shown in eqref:eq:random-surfer:

\begin{align}
\mathbf{T}_{\textrm{RS}} = \mathbf{S} = \alpha \mathbf{T} + (1-\alpha) \mathbf{B}
\label{eq:random-surfer} \end{align}

where:

- $\mathbf{B}$ :: Is matrix of size $n \times n$ such that $\mathbf{B}_{i, j} = \frac{1}{n}, \enspace \forall i,j \in \left[1, n\right]\cap \mathbb{N}$
- In the literature $\alpha$ is often referred to as a damping factor see
  cite:berkhoutRankingNodesGeneral2018a,brinkmeierPageRankRevisited2006a,fuDampingFactorGoogle2006,kamvarAdaptiveMethodsComputation2004b,bianchiniPageRank2005
  or a smoothing constant cite:koppelMeasuringDirectIndirect2014 .

** Power Walk
The random surfer model eqref:eq:random-surfer, however, assumes that all edges are an edorsement of
the target, i.e. they are weighted positively, the power walk method
cite:parkPowerWalkProceedings2013, shown in eqref:eqref:eq:power-walk-method, takes a
different approach to create a /transition probability matrix/ $(\mathbf{W})$ and is compatible
with a negatively weighted edges:

\begin{align}
\mathbf{W}_{i, j} &= \frac{\beta^{\mathbf{A'}{i, j}}}{\sum^{n}_{j = 1} \left[
\beta^{a_{i, j}} \right]} \label{eqref:eq:power-walk-method} \end{align}


where:

- $\mathbf{A'}$ :: is a weighted adjacency matrix such that $\mathbf{A}_{i, j} \in \mathbb{R}$
- $x$ :: is the probability of travelling to a vertex for which there is no connection.
  + Similarly to eqref:eq:random-surfer , $x = \frac{1-\alpha}{n}$
- $\mathbf{\beta}$ :: is the ratio of probability between following an edge and
  making a jump to a vertex for which there is no path
  + i.e. $\beta x$ is the probability of following a path with a weight of 1.

** Solving the stationary distribution
:PROPERTIES:
:CUSTOM_ID: iterative-power-method
:END:
Solving the EigenValue problem for a large matrix can be very resource
intensive, for example /Wikipedia/ currently has over 6, 000, 000 pages
cite:WikipediaSizeWikipedia2020 which would correspond to an adjacency matrix
with over $10^{12}$ entries, yet even a relatively fast compiled language like
/Julia/ can struggle to solve the eigen vectors for a matrix of size
$(10^{4})^{2}$ as shown in listing [[eigen-julia]].

The power method, first mentioned in section [[#stationary-distribution]], is a
better suited approach, with respect to performance, because:

1. The method is only looking for one solution
2. The accuracy of the solution (measured by  $\exists\eta\in \mathbb{R}$) can be tuned to improve performance.
  


#+NAME: eigen-julia
#+CAPTION: Time to Solve Eigen Value for matrix of size n
#+begin_src julia :results output
using LinearAlgebra using TimerOutputs

function time_eigenvec(n)
    T = [ x-n+n*y for x in rand(n), y in rand(n) ]
    t = @elapsed eigvecs(T) return t end

time_eigenvec(10^2) time_eigenvec(10^3)
# time_eigenvec(10^4) # times out
#+end_src

#+RESULTS: eigen-julia
: time_eigenvec (generic function with 1 method)
: 0.072302487
: 0.814937083

* Proposed Research
Consider the ordered set of EigenVectors eqref:eq:eigen-set of a positive
transition probability matrix such as $\mathbf{S}$ eqref:eq:random-surfer or
$\mathbf{T}$ eqref:eq:stationary-distribution:

\begin{align}
\{ \lambda_{k} \mid \enspace  \lambda_{k} < \lambda_{k-1}, \enspace k\in \mathbb{Z}^{+} \leq n \} \label{eq:eigen-set}
\end{align}

** Dominant EigenVector
It has been shown that $\lambda_{k} \leq 1, \enspace \forall k \leq n$ and that
the dominant [fn:dom] $\lambda$ can be computed by the /power method/,
cite:farahatAuthorityRankingsHITS2006 and that this solution can be reached in a limited number of steps ($\approx 50$) for graphs on the order of a million vertices [[cite:bianchiniPageRank2005][p. 123]] (assuming that $\alpha \in \left[0, 1\right]$ is not too close to 1, in which case convergence can become quite slow cite:tanNewExtrapolationMethod2017a)

** Stability and Convergence
:PROPERTIES:
:CUSTOM_ID: stability-convergence
:END:
How quickly the /Power Method/ converges depends on the magnitude of $\mid \lambda_{2} \mid$. cite:bryan250000002006

With respect to the random surfer model eqref:eq:random-surfer, It has been shown
that $\mid \lambda_{2} \mid \leq \alpha$ and if the corresponding graph contains
two or more irreducible closed subgraphs that the $\mid \lambda_{2} \mid = \alpha$, this is demonstrated in listing [[random-surf-r]]
and figure [[two-sub-graph]].

It has also been shown that an $\alpha$ value near 1 will imply an unstable stationary distribution cite:ngStableAlgorithmsLink2001 that converges slowly cite:tanNewExtrapolationMethod2017a, this is because a small change to the corresponding graph could lead to $\lambda_{1} \leftrightarrow \lambda_{2}$ and hence different eigenvectors will correspond to the solution as shown in eqref:eq:eigen-one

** Choosing $\alpha$
:PROPERTIES:
:CUSTOM_ID: choosing-alpha
:END:
Although section [[#stability-convergence]] might suggest that smaller values of
$\alpha$ may be more ideal, it is worth recalling that as $\alpha$ is reduced
the probability of a random walk visiting any other vertex will become more and
more uniform because $\frac{1-\alpha}{n} \rightarrow \frac{1}{n}$ as $\alpha
\rightarrow 0$. cite:parkPowerWalkRevisiting2013

The value used originally by Page and Brin was $\alpha = 0.85$ See
[[cite:larrypageAnatomyLargescaleHypertextual1998][p. 109]] and this appears to
have widely adopted.
cite:kamvarAdaptiveMethodsComputation2004b,boldiPageRankFunctionDamping2005,
however research suggests that modifying the value by be useful in detecting
spam
cite:zhangMakingEigenvectorBasedReputation2004,boldiPageRankFunctionDamping2005


#+NAME: random-surf-r
#+CAPTION: Implementing the random surfer model for the graph shown in figure [[my-graph]]
#+begin_src R :session graph-two :results output :exports code
library(igraph)
library(tidyverse)

g1 <- igraph::graph.formula(1++2, 1+-8, 1+-5, 2+-5, 2+-7, 2+-8, 2+-6, 2+-9, 3++4, 3+-5, 3+-6, 3+-9, 3+-10, 4+-9, 4+-10, 4+-5, 5+-8, 6+-8, 7+-8)

A <- igraph::get.adjacency(g1, names = TRUE, sparse = FALSE) %>%
  as.matrix()

## Adjust the Order
A <- A[order(as.integer(row.names(A))), order(as.integer(colnames(A)))]

adj_to_probTrans <- function(adjMat) {
  t(adjMat) %*% diag(1/colSums(t(adjMat)))
}

B <- matrix(rep(1/nrow(T), length.out = nrow(T)**2), nrow = nrow(T))
ɑ <- 0.123456789

S <- ɑ*T+(1-ɑ)*B


eigen(S, symmetric = FALSE)$values


## [1]  1.000000e+00 -1.234568e-01  1.234568e-01 -1.234568e-01  2.231012e-10
## [6] -2.231012e-10 -8.488298e-18  3.570154e-18 -1.450336e-20  9.629650e-35
#+end_src

#+NAME: two-sub-graph-code
#+CAPTION: Figure of a graph with two subgraphs, identical to graph published by Park and Simoff cite:parkPowerWalkProceedings2013
#+begin_src R :session graph-two :results output graphics file :file two-sub-graph-fig2.png :exports results
plot(g1)
#+end_src


#+NAME: two-sub-graph
#+CAPTION: Graph with two closed irreducible subgraphs
#+RESULTS[377d90f1148806c31aca042e87490655e75517cf]: two-sub-graph-code
[[file:two-sub-graph-fig2.png]]

** Research Question
:PROPERTIES:
:CUSTOM_ID: research-question
:END:

It is not clear how $\lambda_{2}$ behaves with respect to the /Power Walk/ method, eqref:eqref:eq:power-walk-method although it has been shown that under specific circumstances the value of $\mid \lambda_{2}\mid$ can be predicted from the method parameters and properties of the graph. [[cite:parkPowerWalkProceedings2013][\textsection 3.4]]

This research will involve investigating the relationship between the second eigenvalue of the /Power Walk/ transition matrix and the features of a graph corresponding to some type of network (e.g. a social network, webpages, wiki, etc.)

In particular, open questions are whether or not the value of the second eigenvalue can:

- be predicted from the parameters of the model and/or features of the graph
  + e.g. some function of $\alpha$
- indicate the stability of the stationary distribution of a
- indicate how quickly the /Power Method/ will converge to a solution

* TODO Literature Review
** Introduction
** Body
Structure the literature in a logical way
*** Different Sources


** To Sort out
- Using Wikipedia to alleviate data sparsity issues in recommender systems
  - cite:loizouUsingWikipediaAlleviate2010a
  - The relationships in Wikipedia are very useful, we can use them sort of like
    a model, by mapping topics to articles and leveraging the interlinked pages
    we might be able to extrapolate that back out to useful recommendations.
- /Network analysis of usergenerated content quality in Wikipedia/
  + cite:ingawaleNetworkAnalysisUser2013a
    - Can We relate Social Media to Wikipedia with respect to quality
- Consensus Based Ranking Wikipedia cite:nemaConsensusbasedRankingWikipedia2017a
  + Bias the $\alpha$ assumption to favour websites that are more often visited in practice:
    - Thoughts: Could be dicy because nobody is going to the second page of Google.
* Literature Review
:PROPERTIES:
:CUSTOM_ID: summary-lit-review
:END:

The proposed research (see section [[#research-question]]) relates broadly to the /PageRank/ method, Random-Surfer model, sentiment
analysis and graph centrality, for which material is quite abundant, although much
of the literature is concerned with either:

1. The original /PageRank/ method developed by Page and Brin,
cite:larrypageAnatomyLargescaleHypertextual1998 OR
2. Modifying the pagerank method to improve upon:
  + Precision and accuracy see cite:ngStableAlgorithmsLink2001,berkhoutRankingNodesGeneral2018a,nemaConsensusbasedRankingWikipedia2017a,fuDampingFactorGoogle2006
  + Performance with respect to:
    - Rate of convergence in terms of iterations and time, see cite:tanNewExtrapolationMethod2017a,langvilleReorderingPageRankProblem2006
    - Stability of any given solution, see cite:ngStableAlgorithmsLink2001

Although neither of these points are a direct analogue for the proposed
research, which relates in itself to a modified /PageRank/ algorithm, much of
the work will be very similar in approach and hopefully offer much insight upon
closer inspection.

** Building on Literature Referred to in Primary Resource
This research is focused primarily on the /Power Walk/ method or approach to the
PageRank algorithm proposed by Park and Simoff in a 2013 conference paper,
cite:parkPowerWalkProceedings2013 this paper contained some discussion of
relevant research.
*** Stability and Convergence
:PROPERTIES:
:CUSTOM_ID: stability-convergence-lit-review
:END:

Haveliwala and Kamvar cite:haveliwalaSecondEigenvalueGoogle2003 proved that
$\lambda_{2}$ (see eqref:eq:eigen-set) is bounded above by the smoothing
constant $\alpha$ and in the case that the corresponding graph has more than 1
closed subgraph is equal to $\alpha$. This is an important revelation because it
has been shown that the further the second eigenvalue is from 1, the more
resistant the stationary distriubtion of the pagerank is to perturbations in the
corresponding graph, cite:ngStableAlgorithmsLink2001 and the faster the pagerank
will converge cite:bryan250000002006.

It has been shown that the /power method/ (see section [[#iterative-power-method]])
will always converge $\forall \alpha <1$ cite:bianchiniPageRank2005 and that an
$\alpha$ closer to the value of 1 does not necessarily correspond to a more
meaningful ranking, cite:boldiPageRankFunctionDamping2005 hence, given the upper
bound of $\lambda_{2} \leq \alpha$, the value of $\alpha$ can be tuned away from
1 in order to improve the convergence and stability of the /PageRank/ (however a
value of $\alpha$ that is too small will indeed be meaningless as discussed in
section [[#choosing-alpha]]). cite:parkPowerWalkRevisiting2013

This works provides a framework for considering the method parameters and
$\lambda_{2}$ with respect to the convergence and stability of the /Power Walk/
method.

*** Building on the Random Surfer

Related work referred to in the paper has involved using community ratings of
web pages to improve upon the /PageRank/ method
cite:parkMiningWebMultiresolution2007, similar work has also been researched
more recently that found a combination of usage statistics and content quality
scores can significantly improve the precision and accuracy of the page rank
method. cite:nemaConsensusbasedRankingWikipedia2017a

Such a strategy is however limited to websites that make usage statistics
public, such as wikis.

An extension to this research could involve an investigation into the precision
of the /Power Walk/ method in conjuction with usage statistics compared with the
/Power Walk/ method.

**** Wikis
:PROPERTIES:
:CUSTOM_ID: wiki-networks
:END:

There is literature suggesting that the network structure of wiki articles can
be an important feature in the emergence of quality
cite:ingawaleNetworkAnalysisUser2013a, related work also shows that /Wikipedia/
can be used to improve performance of recommender systems when there is limited
data cite:loizouUsingWikipediaAlleviate2010a and it would be very interesting to
see how the /Power Walk/ method would perform compared to the /PageRank/ method
in those situations.

** Page Rank
*** Building on the /PageRank/ Method
The /PageRank/ method is a relatively versatile approach[fn:vers] that is
relatively robust to manipulation compared with other methods for dealing with
information retrieval, cite:langvilleSurveyEigenvectorMethods2005 perhaps for
this reason there is much literature on modifying the /PageRank/ method to
improve upon it as discussed generally in section [[#summary-lit-review]].

Choosing a smoothing constant, however, is somewhat difficult task because it can have an
impact on the behaviour of the model (see cite:fuDampingFactorGoogle2006 and  section
[[#stability-convergence-lit-review]]) but also because without empirical guidance
it can feel somewhat arbitrary, there is an approach in the literature that
involves using input/output ratios to determine an appropriate value
cite:fuDampingFactorGoogle2006 and another that seeks to use structural network
dynamics to provide a score distribution and obviate the need for a smoothing
constant entirely. cite:berkhoutRankingNodesGeneral2018a

It is not entirely clear if this approach will offer much to this method but a
more careful inspection may reveal helpful perspectives.
*** Stability and Convergence
Improving the rate of convergence of the /PowerRank/ is obviously desirable and
there has been considerable mathematical resarch to develop better algorithms.

As previously mentioned in, the stability and convergence of the /Power Rank/
method is poor when the smoothing constant $\alpha$ is close to 1, a 2016 paper
published in the /Journal of Computational and Applied Mathematics/
cite:tanNewExtrapolationMethod2017a found that the trace of a matrix can be used
to produce a considerably more efficient approach to solve the /PageRank/ for
values of $\alpha$ near 1. It is not clear how relevant this is given that
$\alpha$ values near 1 offer no improvement in precision
cite:boldiPageRankFunctionDamping2005 and that the solution is unstable
cite:ngStableAlgorithmsLink2001 (see sections [[#choosing-alpha]] and
[[#stability-convergence]]), but, it is yet to be shown if these characteristics
necessarily apply to the /Power Walk/ method and such an approach may prove to
be insighful nonetheless.

Another approach involves involves reordering the problem and taking advantage
of the fact that the transition probability matrix is sparse [fn:sprs] in order
to produce a new algorithm which cannot perform worse than the /power method/
but has been shown to improve the rate of convergence in certain cases.
cite:langvilleReorderingPageRankProblem2006.

*** Insightful Miscellaneous Work
**** PageRank as a Power Series
:PROPERTIES:
:CUSTOM_ID: power-series
:END:
Research has shown that the /PageRank/ Method can be expressed as a power series
and an algorithm for calculating the page rank derived,
cite:brinkmeierPageRankRevisited2006a the solution corresponds to the /power
method/ but a slightly faster algorithm is also presented. Seperate work has
been undertaken to similarly express the PageRank in terms of a /McLaurin
Series/, finding that each partial sum of the series corresponds to an iteration
of the /power method/. cite:boldiPageRankFunctionDamping2005 This work is
extremely relevant to the /Power Walk/ method because the exponent in that
method (see eqref:eqref:eq:power-walk-method) suggests that an generating
function such as $f(x) = \sum^n_{i=0} \left[ x^n \frac{a}{n!} \right]$ may be
able to show a more direct relationship between the /PowerRank/ and /Power Walk/
approaches.


**** Modelling
The pageRank method has been leveraged as a value to assist in building
artificial networks in order to model real-world networks, such networks have
been shown to have upper and lower bounds on there diamaters.
cite:mehrabianItSmallWorld2016 this is a very interesting area of research and
it would be interesting to see whether or not the use of the /Power Walk/ method
in such an approach produces graphs that are more consistent with social
networks.

**** Pure Mathematics
One very interesting application of the pagerank method in the literature was
appying the /PageRank/ method to graph of integers (see figure [[pure-math-graph]])
with edges based on divisors, as shown in listing [[pure-math-adj]].

This is well outside the scope of this research, but if the precision of the
power walk method is found to be reasonably good, it would make for a very
interesting exercise to measure it's performance at predicting integers and
attempting to find relationships between the two.

Another paper outside the scope of this paper is work by Ding & Li concerned
with extending the /PageRank/ method to /multi-plex/ graphs[fn:mp], although
very interesting and practical this research is beyond the scope of this work.
** Search Engine Optimisation
There is a considerable amount of work in the literature concerning the
relationship between the /PageRank/ method and Search Engine optimisation, such
as:

- Using machine learning to inductively model search engines cite:pringleWhatTallPoppy1998
- Methods to solve the optimisation problem involved in centring a vertex by
  creating a limited number of edges
  cite:kamvarAdaptiveMethodsComputation2004b,dekerchoveMaximizingPageRankOutlinks2008
  + Consider a website trying to maximise exposure for example
  + Related papers consider also keyword frequency, see for example cite:zhangImpactWebpageContent2005

Such literature however is suited to an ex post facto study and is hence not
terribly relevant to the proposed research.
** Skimming and summary
*** From Paper
**** DONE [#A] Stable Algorithms for Link Analysis cite:ngStableAlgorithmsLink2001 :modification:insight:eigenvalue:
Investigates under what situations the pagerank of a matrix is resistant to perturbations of a graph, finding essentially that distance of $\lambda_{2}$ from 1 is important.

A new algorithm is suggested
**** DONE [#A] The second EigenValue of the Google Matrix cite:haveliwalaSecondEigenvalueGoogle2003,zhaoOptimizingNodeDiscovery2019 :eigenvalue:
Determine analytically the modulus of the second EigenValue for the /PageRank/ method.

provides that $\lambda_{2} \leq \alpha$ and if there are 2 or more irreducible subgraphs $\lambda_{2}=\alpha$.

This important for the rate of convergence of the algorithm.

**** DONE [#B] Community Based popularity cite:parkMiningWebMultiresolution  :modification:
A more general form of page rank using popularity scores dependent on a
community rating can be used to improve precision.
This is similar to the statsrank method cite:nemaConsensusbasedRankingWikipedia2017a
**** WAITING [#B] Linear Algebra behind Google cite:bryan250000002006        :insight:
A discussion on the algebra behind the pagerank method.
*** DONE Wikipedia
**** DONE [#A] Network analysis of user generated content quality in Wikipedia  cite:ingawaleNetworkAnalysisUser2013a

Is there a relationship between content quality and the structure of connections? Can high quality Wikipedia pages be used as a benchmark for the structure of connections.

The network structure of interactions between articles plays an important role in the emergence of quality.

High quality articles clusture in hubs.

**** DONE [#B] Using Wikipedia to alleviate data sparsity issues in Recommender Systems cite:loizouUsingWikipediaAlleviate2010a
For Recommender systems with limited access to data, Wikipedia can be used as an analogue with respect to connections to significantly improve performance.
*** DONE Page Rank
**** DONE General
***** DONE [#C] Inside PageRank cite:bianchiniPageRank2005                  :general:

This is a discussion on the stability, complexity and critical role of parameters involved in the computation.

- The page rank method will always converge for the random surfer eqref:eq:random-surfer provided that $\alpha < 1$ [[cite:bianchiniPageRank2005][\textsection 2.2]]

***** DONE [#C] survey of eigenvectors for web info cite:langvilleSurveyEigenvectorMethods2005 :general:
Many methods for web information retrival involve eigen vectors.

PageRank is impervious to spamming.
**** DONE Modification
***** DONE [#A] Ranking Nodes in Networks cite:berkhoutRankingNodesGeneral2018a :modification:
The choice of damping factor of Googles page rank might have a large impact on the values given to vertices.

This suggests an approach that uses structural network dynamics to provide an appropriate score distribution.

The method implemented is not something I have come yet to understand, but it could be very interesting to see:

- how it relates to the power walk method
- whether or not it could offer insightts into the convergence and stability of the power walk method
- Whether or not the method would be compatible with negatively weighted edges.

***** DONE [#A] Consensus based raking of Wikipedia cite:nemaConsensusbasedRankingWikipedia2017a :modification:
Google's page rank method can be improved by replacing the background probability of $\frac{1}{n}$ with statistics of usage, this is referred to as the StatsRank, this can be aggregated with user opinion to give the ConsensusRank

A limitation of this approach is that usage stats are only really available, in a neutral fashion for wikis, so too bad.

***** DONE [#B] Modified Page Rank Algorithm for Biology cite:zhangModifiedPageRankAlgorithm2018 :modification:

The page rank method can be used for modelling gene expression.

***** DONE [#B] Damping factor in Google Page Ranking cite:fuDampingFactorGoogle2006 :modification:
The damping factor is critical in changing a website's ranking in a search, this
modified algorithm, based on input-output ratio is proposed to substitute for
the damping factor.

It would be interesting to determine whether or not this type of a substitution
could improve the performance of the /power walk/ method and what implications
it would have on the method parameters and resulting convergence and stability.

**** DONE Performance
***** DONE [#A] A New Extrap method for PageRank computations cite:tanNewExtrapolationMethod2017a :performance:

A new algorithm can be used to improve the convergence rate of the power rank
method, compared to the /power method/ when the smoothing constant $\alpha$ is
near 1, when using the trace of a matrix.

***** DONE [#A] Reordering for the pagerank cite:langvilleReorderingPageRankProblem2006 :performance:
Reordering the pagerank problem and taking advantage of the fact that it is
sparse can allow for an improved algorithm that can potentially improve
performance or at worst offer no compromise in performance.
**** DONE Insight
***** DONE [#A] Power Series
****** DONE [#A] Page Rank Revisited cite:brinkmeierPageRankRevisited2006a :insight:
The Page Rank method can be expressed as a power series and an algorithm for
calculating the page rank can be derived, this corresponds to the /power method/
but offers insights into the mechanisms of the method.

A slightly faster algorithm is suggested at \textsection 6.3.

This is quite interesting because expressing the power walk method as a power
series may offer insights with respect to the convergence and stability of the
algorithm
****** DONE [#A] Page rank as a function of the damping factor cite:boldiPageRankFunctionDamping2005 :insight:

Demonstrates the behaviour of page rank for varying values of \alpha.

Values nearer to 1 do not give a more meaningful ranking.

Relate it toMcLaurin series Using iteration i.e. (the power rankmethod) gives the same exact result as the power series at the same step, similar to what was shown by brinkmeier cite:brinkmeierPageRankRevisited2006a

This could be useful in developing analytical methods to solve the pagerank problem.
***** DONE [#B] Small World for Random Surfers cite:mehrabianItSmallWorld2016 :insight:
Graphs can be generated in order to model real world networks, these models can
use the degree or page rank of a given vertex as a parameter to create the next
vertex in generating the graph.

This paper discusses upper and lower bounds for the diameter of a graph generated using random-surfer web-graph model.
***** DONE [#B] Centrality ranking in Multiplex Networks cite:dingCentralityRankingMultiplex2018 :insight:

A technique to measure node centrality for a multi-dimensional graph.

***** DONE [#B] Google's Page Rank                                          :insight:
A Discussion of the Math behind googles page rank

***** DONE [#C] PageRank of Integers                                        :insight:
Page rank can be used in pure mathematics.
*** TODO SEO
**** DONE [#A] Adaptive Methods for computation of page rank cite:kamvarAdaptiveMethodsComputation2004b :discoverability:
Given a graph, how can we optimise the discoverability of a node by introducing a couple of edges. A node is considered as discoverable if it:

1. Has a high page rank value
2. The number of steps to reach that vertex from another vertex is low.

**** DONE [#B] Maximizing Page Rank                                          :discoverability:insight:
How can a domain be modified to improve it's page rank?

Provides an optimal linkage strategy

**** DONE [#B] What is a tall poppy among web pages cite:WhatTallPoppy1998   :discoverability:
With a training set of collected pages from typical queries a decision tree
based machine learning algorithm is used to model a decision tree for a variety
of search engines.

Not totally relevant but a very interesting project and approach.
**** DONE [#C] Analysing google through SEO Data cite:AnalysingGoogleRankings
Page Rank is an important feature of Search Engine Optimisation
**** DONE [#C] impact of webpage content characteristics on webpage visibility cite:zhangImpactWebpageContent2005 :discoverability:
Webpage visibility can be improved by increasing the frequency of keywords

* Footnotes

[fn:mp] Multi-plex, in this case, refers to edges between vertices accross
different dimensions, for example a link from a webpage to a food outlet could
be made by way of a hyperlink, a phone number and a street address, this would
be 3 different types of edges between two vertecies and so would be multi-plex.

[fn:sprs] if an adjacency matrix and/or corresponding probability transition matrix were not sparse each vertex would be like an index, which is unlikely

[fn:vers] The approach has even been used in conjuction with linear regression to map gene expresseions, see cite:zhangModifiedPageRankAlgorithm2018

[fn:dom] Dominant in this case refers to the the largest $\mid \lambda_{k} \mid$
