#+TITLE: Relationship of Model Parameters and Solution Stability in the Power Walk Page Rank Method.
:PREAMBLE:
# #+OPTIONS: broken-links:auto todo:nil H:9
#+OPTIONS: broken-links:auto H:9
#+OPTIONS: broken-links:auto
#+INFOJS_OPT: view:showall toc:3
#+PLOT: title:"Citas" ind:1 deps:(3) type:2d with:histograms set:"yrange [0:]"
#+OPTIONS: tex:t
#+TODO: TODO IN-PROGRESS WAITING DONE
#+CATEGORY: DProj
:END:
:HTML:
#+INFOJS_OPT: view:info toc:3
#+HTML_HEAD_EXTRA: <link rel="stylesheet" type="text/css" href="../resources/style.css">
#+CSL_STYLE: ../resources/nature.csl
:END:
:R:
#+PROPERTY: header-args:R :session TADMain :dir ./ :cache yes :eval :exports both
#+PROPERTY: header-args :eval never-export
:END:
:LATEX:
#+LATEX_HEADER: \IfFileExists{../resources/style.sty}{\usepackage{../resources/style}}{}
#+LATEX_HEADER: \IfFileExists{../resources/referencing.sty}{\usepackage{../resources/referencing}}{}
#+LATEX_HEADER: \addbibresource{../resources/references.bib}
:END:
* Introduction

Much information is interconnected, be it an article, research paper, movie,
books, personal notes, knowledge bases, peronal releationships etc., this
interconnectivity creates a network which can naturally visualised as a graph.

Determining which vertex of such a graph is most central is useful as it may
assist in research, learning and collaborating. The /Page Rank/ method, which
originally underpinned [[www.google.com][Google]]'s search-engine, essentially asserts that the
centre most vertex of a graph could be considered the vertex that has the
highest probability of being a destination following a random walk
cite:larrypageAnatomyLargescaleHypertextual1998, although this method is
popular, it does not however, easily adapt to negatively weighted edges (a
negative weight in this case measuring dissaproval or an aversion to follow that
link, like an advertisement, as opposed to endorsement). A limitation which is
increasingly important as the area of /Sentiment Analysis/ within the field of
/Text Mining/ is developed. cite:parkPowerWalkProceedings2013

The /Power Walk/ Method is similar to the /Random Surfer/ model but takes a
different approach in order to accomadate the potential for an edge to have any
arbirary real weight. cite:parkPowerWalkProceedings2013

This research project will be an investigation into the relationship between
model parameters and the solution stability of the /Power Walk/ method.

** Motivation

Taking advantages of inter-related ideas allows for exploratory research which
can promote both a deeper and broader understading of a topic, an example of
this is the concept of a /pathfinder/, which is a list of central sources for a
topic that can help in early stages of literature searches,
cite:harbesonTeachingReferenceBibliography1972
Examples of such Pathfinders include:

- Institution examples:
  + [[https://libraries.mit.edu/experts/][/M.I.T./]] cite:mitResearchGuidesExpert
  + [[https://guides.library.harvard.edu/][/Harvard/]] cite:harvarduniversityResearchGuides
  + [[https://www.lib.berkeley.edu/libraries/business-library][Berkley University]] cite:berkleyuniversityBusinessLibraryUC
  + [[https://www.loc.gov/rr/scitech/tracer-bullets/][/Library of Congress/]] cite:ScienceTracerBullets
    - The Library of Congress refers to a /PathFinder/ as a /Tracer Bullet/, which is both a very descriptive and very American name.
- Wiki Examples:
  + [[http://mathonline.wikidot.com/][Math Online]]  cite:Mathonline
  + [[https://brilliant.org/wiki/best/][Top /Brilliant/ Wiki Pages]] cite:Top100Wiki
  + [[https://www.mediawiki.org/wiki/Help:Categories][Category Pages within MediaWiki Sites]] cite:HelpCategoriesMediaWiki
    + For example the [[https://en.wikipedia.org/wiki/Category:Mathematics][Mathematics Category Page]] cite:CategoryMathematics2019

Using /Wikipedia/ for example can make for a very effective subject guide by
following the various hyperlinks across wikipedia and leveraging [[https://www.mediawiki.org/wiki/Help:Categories][Category Pages]]
cite:HelpCategoriesMediaWiki in order to map out a topic while referring to
references as necessary. Such a strategy even recommended by some [[https://mville.libguides.com/c.php?g=370066&p=2500344][Library Study
Guides]] cite:moskowitzLibraryGuidesWikipedia, and has even been
implemented in recommendation systems to overcome a lack of data
cite:loizouUsingWikipediaAlleviate2010a (see section of litreview? #CITE).

Similarly the [[https://en.wikipedia.org/wiki/Collective_Knowledge_(software)][/Zettelkasten/ method]] of note taking essentially involves a collection of
small interlinked notes cite:OverviewZettelkastenMethod, much like a wiki,
within the last two decades this method has peaked in popularity
cite:GoogleBooksNgram, despite being a method dating back to atleast the 18th
Century. cite:haarkoetterAllesWesentlicheFindet This is clearly driven in party
by the development of the internet, /HTML/ and the increasing breadth and depth
of human knowledge.

A comprehensive review of the pathfinder approach, however, reveals that many
such subject guides are not consistent with the needs of those engaging in
research on any given topic. cite:vilenoPaperElectronicEvolution2007 This
issue is somewhat analogous to the issue faced by Larry Page and Sergey Brin in
that the centrality of an article of information corresponds very greatly to
it's relevance. cite:larrypageAnatomyLargescaleHypertextual1998

* Background and Rationale
** Background of issue
Given some graph $G(V,E)$ with $\mid V \mid = n$, a corresponding adjacency
matrix $\mathbf{A}$ describes the number of edges between vertex $i$ and $j$,
such that $\mathbf{A}_{i, j}$ represents the number of edges between the
vertices, with respect to a directed graph the entry may either denote:

- $i \rightarrow j$
  - One such example of this implementation being the ~igraph~ library cite:gaborcsardiIgraphManualPages2019
- $j \rightarrow i$ [[cite:nicholsonLinearAlgebraApplications2009][\textsection 2.3]]

While both definitions appear in the literature, the latter definition is more
common/convenient when working with /probability transition matrices/ and will
hence be adopted here.

*** Stationary Distribution
:PROPERTIES:
:CUSTOM_ID: stationary-distribution
:END:
Given this adjacency matrix $\mathbf{A}$, in order to have each element
$\mathrm{A}_{i, j}$ represent the probability of leaving $j$ and travelling to
$i$ during a random walk (as opposed to the number of edges), each column will
need to be scaled to one, this can be acheived with matrix multiplication as
illustrated in eqref:eq:mat-mult-colsum:

\begin{align}
\mathbf{T} = \mathbf{A} \enspace \mathrm{diag}\left( \mathtt{colsums}\left(
\mathbf{A} \right) \right) \label{eq:mat-mult-colsum} \end{align}

The state distribution $\vec{p}_{k}$ describes the probability of visiting each
vertex during a random walk for the $k^{\textrm{th}}$ step of the walk, given
this, the stationary distribution $\vec{p}$ is given by
eqref:eq:stationary-distribution:


\begin{align}
\vec{p_{i}} &= \mathbf{T} p_{i-1} \nonumber \\ \lim_{n \to \infty} \left[
\vec{p_{i}} \right] &= \lim_{n \to \infty} \left[ \mathbf{T} \vec{p_{i-1}}
\right] \nonumber \\ \implies \vec{p} &= \mathbf{T} \vec{p}
\label{eq:stationary-distribution} \end{align}

If $G(V, E)$ is an ergodic graph (i.e. all vertices may be reached from any
initial vertex), this can be solved by iteration (referred to as the /Power
Method/) or by solving the eigenvalue problem for $\lambda=1$ as shown in
eqref:eq:eigen-one:

\begin{align}
\lambda \vec{p} &= \mathbf{T} \vec{p} \nonumber \\ \lambda = 1 \implies \vec{p}
&= \mathbf{T} \vec{p} \label{eq:eigen-one} \end{align}

** Random Surfer
If however a graph is non-ergodic, this random walk will not traverse every
vertex, to overcome this, the /Random Surfer/ model can be implemented
cite:larrypageAnatomyLargescaleHypertextual1998, by essentially introducing,
into the /probability transition matrix/ $(\mathbf{T})$, some probability
$(\frac{1-\alpha}{n})$ of traversing to a disconnected vertex $(V)$, this is
shown in eqref:eq:random-surfer:

\begin{align}
\mathbf{T}_{\textrm{RS}} = \mathbf{S} = \alpha \mathbf{T} + (1-\alpha) \mathbf{B}
\label{eq:random-surfer} \end{align}

where:

- $\mathbf{B}$ :: Is matrix of size $n \times n$ such that $\mathbf{B}_{i, j} = \frac{1}{n}, \enspace \forall i,j \in \left[1, n\right]\cap \mathbb{N}$
- In the literature $\alpha$ is often referred to as a damping factor see
  cite:berkhoutRankingNodesGeneral2018a,brinkmeierPageRankRevisited2006a,fuDampingFactorGoogle2006,kamvarAdaptiveMethodsComputation2004b,bianchiniPageRank2005
  or a smoothing constant cite:koppelMeasuringDirectIndirect2014 .

** Power Walk
The random surfer model eqref:eq:random-surfer, however, assumes that all edges are an edorsement of
the target, i.e. they are weighted positively, the power walk method
cite:parkPowerWalkProceedings2013, shown in eqref:eq:power-walk-method, takes a
different approach to create a /transition probability matrix/ $(\mathbf{W})$ and is compatible
with a negatively weighted edges:

\begin{align}
\mathbf{W}_{i, j} &= \frac{\beta^{\mathbf{A'}{i, j}}}{\sum^{n}_{j = 1} \left[
\beta^{a_{i, j}} \right]} \label{eqref:eq:power-walk-method} \end{align}


where:

- $\mathbf{A'}$ :: is a weighted adjacency matrix such that $\mathbf{A}_{i, j} \in \mathbb{R}$
- $x$ :: is the probability of travelling to a vertex for which there is no connection.
  + Similarly to eqref:eq:random-surfer , $x = \frac{1-\alpha}{n}$
- $\mathbf{\beta}$ :: is the ratio of probability between following an edge and
  making a jump to a vertex for which there is no path
  + i.e. $\beta x$ is the probability of following a path with a weight of 1.

** Solving the stationary distribution
Solving the EigenValue problem for a large matrix can be very resource
intensive, for example /Wikipedia/ currently has over 6, 000, 000 pages
cite:WikipediaSizeWikipedia2020 which would correspond to an adjacency matrix
with over $10^{12}$ entries, yet even a relatively fast compiled language like
/Julia/ can struggle to solve the eigen vectors for a matrix of size
$(10^{4})^{2}$ as shown in listing [[eigen-julia]].

The power method, first mentioned in section [[#stationary-distribution]], is a
better suited approach, with respect to performance, because:

1. The method is only looking for one solution
2. The accuracy of the solution (measured by  $\exists\eta\in \mathbb{R}$) can be tuned to improve performance.
  


#+NAME: eigen-julia
#+CAPTION: Time to Solve Eigen Value for matrix of size n
#+begin_src julia :results output
using LinearAlgebra using TimerOutputs

function time_eigenvec(n)
    T = [ x-n+n*y for x in rand(n), y in rand(n) ]
    t = @elapsed eigvecs(T) return t end

time_eigenvec(10^2) time_eigenvec(10^3)
# time_eigenvec(10^4) # times out
#+end_src

#+RESULTS: eigen-julia
: time_eigenvec (generic function with 1 method)
: 0.072302487
: 0.814937083

* Proposed Research
Consider the ordered set of EigenVectors eqref:eq:eigen-set of a positive
transition probability matrix such as $\mathbf{S}$ eqref:eq:random-surfer or
$\mathbf{T}$ eqref:eq:stationary-distribution:

\begin{align}
\{ \lambda_{k} \mid \enspace  \lambda_{k} < \lambda_{k-1}, \enspace k\in \mathbb{Z}^{+} \leq n \} \label{eq:eigen-set}
\end{align}

** Dominant EigenVector
It has been shown that $\lambda_{k} \leq 1, \enspace \forall k \leq n$ and that
the dominant [fn:dom] $\lambda$ can be computed by the /power method/,
cite:farahatAuthorityRankingsHITS2006 and that this solution can be reached in a limited number of steps ($\approx 50$) for graphs on the order of a million vertices [[cite:bianchiniPageRank2005][p. 123]] (assuming that $\alpha \in \left[0, 1\right]$ is not too close to 1, in which case convergence can become quite slow cite:tanNewExtrapolationMethod2017a)

** Stability and Convergence
:PROPERTIES:
:CUSTOM_ID: stability-convergence
:END:
How quickly the /Power Method/ converges depends on the magnitude of $\mid \lambda_{2} \mid$. cite:bryan250000002006

With respect to the random surfer model eqref:eq:random-surfer, It has been shown
that $\mid \lambda_{2} \mid \leq \alpha$ and if the corresponding graph contains
two or more irreducible closed subgraphs that the $\mid \lambda_{2} \mid = \alpha$, this is demonstrated in listing [[random-surf-r]]
and figure [[two-sub-graph]].

It has also been shown that an $\alpha$ value near 1 will imply an unstable stationary distribution cite:ngStableAlgorithmsLink2001 that converges slowly cite:tanNewExtrapolationMethod2017a, this is because a small change to the corresponding graph could lead to $\lambda_{1} \leftrightarrow \lambda_{2}$ and hence different eigenvectors will correspond to the solution as shown in eqref:eq:eigen-one

** Choosing $\alpha$
Although section [[#stability-convergence]] might suggest that smaller values of $\alpha$ may be more ideal, it is worth recalling that as $\alpha$ is reduced the probability of a random walk visiting any other vertex will become more and more uniform because $\frac{1-\alpha}{n} \rightarrow \frac{1}{n}$ as $\alpha \rightarrow 0$.

The value used originally by Page and Brin was $\alpha = 0.85$ See [[cite:larrypageAnatomyLargescaleHypertextual1998][p. 109]] and this appears to have widely adopted. cite:kamvarAdaptiveMethodsComputation2004b,boldiPageRankFunctionDamping2005, however research suggests that modifying the value by be useful in detecting spam cite:zhangMakingEigenvectorBasedReputation2004,boldiPageRankFunctionDamping2005


#+NAME: random-surf-r
#+CAPTION: Implementing the random surfer model for the graph shown in figure [[my-graph]]
#+begin_src R :session graph-two :results output :exports code
library(igraph)
library(tidyverse)

g1 <- igraph::graph.formula(1++2, 1+-8, 1+-5, 2+-5, 2+-7, 2+-8, 2+-6, 2+-9, 3++4, 3+-5, 3+-6, 3+-9, 3+-10, 4+-9, 4+-10, 4+-5, 5+-8, 6+-8, 7+-8)

A <- igraph::get.adjacency(g1, names = TRUE, sparse = FALSE) %>%
  as.matrix()

## Adjust the Order
A <- A[order(as.integer(row.names(A))), order(as.integer(colnames(A)))]

adj_to_probTrans <- function(adjMat) {
  t(adjMat) %*% diag(1/colSums(t(adjMat)))
}

B <- matrix(rep(1/nrow(T), length.out = nrow(T)**2), nrow = nrow(T))
ɑ <- 0.123456789

S <- ɑ*T+(1-ɑ)*B


eigen(S, symmetric = FALSE)$values


## [1]  1.000000e+00 -1.234568e-01  1.234568e-01 -1.234568e-01  2.231012e-10
## [6] -2.231012e-10 -8.488298e-18  3.570154e-18 -1.450336e-20  9.629650e-35
#+end_src

#+NAME: two-sub-graph-code
#+CAPTION: Figure of a graph with two subgraphs, identical to graph published by Park and Simoff cite:parkPowerWalkProceedings2013
#+begin_src R :session graph-two :results output graphics file :file two-sub-graph-fig2.png :exports results
plot(g1)
#+end_src


#+NAME: two-sub-graph
#+CAPTION: Graph with two closed irreducible subgraphs
#+RESULTS[377d90f1148806c31aca042e87490655e75517cf]: two-sub-graph-code
[[file:two-sub-graph-fig2.png]]

** Research Question
:PROPERTIES:
:CUSTOM_ID: research-question
:END:

It is not clear how $\lambda_{2}$ behaves with respect to the /Power Walk/ method, eqref:eqref:eq:power-walk-method although it has been shown that under specific circumstances the value of $\mid \lambda_{2}\mid$ can be predicted from the method parameters and properties of the graph. [[cite:parkPowerWalkProceedings2013][\textsection 3.4]]

This research will involve investigating the relationship between the second eigenvalue of the /Power Walk/ transition matrix and the features of a graph corresponding to some type of network (e.g. a social network, webpages, wiki, etc.)

In particular, open questions are whether or not the value of the second eigenvalue can:

- be predicted from the parameters of the model and/or features of the graph
  + e.g. some function of $\alpha$
- indicate the stability of the stationary distribution of a
- indicate how quickly the /Power Method/ will converge to a solution

* TODO Literature Review
** Introduction
** Body
Structure the literature in a logical way
*** Different Sources


** To Sort out
- Using Wikipedia to alleviate data sparsity issues in recommender systems
  - cite:loizouUsingWikipediaAlleviate2010a
  - The relationships in Wikipedia are very useful, we can use them sort of like
    a model, by mapping topics to articles and leveraging the interlinked pages
    we might be able to extrapolate that back out to useful recommendations.
- /Network analysis of usergenerated content quality in Wikipedia/
  + cite:ingawaleNetworkAnalysisUser2013a
    - Can We relate Social Media to Wikipedia with respect to quality
- Consensus Based Ranking Wikipedia cite:nemaConsensusbasedRankingWikipedia2017a
  + Bias the $\alpha$ assumption to favour websites that are more often visited in practice:
    - Thoughts: Could be dicy because nobody is going to the second page of Google.

** Skimming and summary
*** From Paper
**** [#A] Stable Algorithms for Link Analysis :modification:insight:eigenvalue:
Investigates under what situations the pagerank of a matrix is resistant to perturbations of a graph, finding essentially that distance of $\lambda_{2}$ from 1 is important.

A new algorithm is suggested
**** [#A] The second EigenValue of the Google Matrix cite:haveliwalaSecondEigenvalueGoogle2003 :eigenvalue:
Determine analytically the modulus of the second EigenValue for the /PageRank/ method.

provides that $\lambda_{2} \leq \alpha$ and if there are 2 or more irreducible subgraphs $\lambda_{2}=\alpha$.

This important for the rate of convergence of the algorithm.

**** [#B] Community Based popularity cite:parkMiningWebMultiresolution :modification:
A more general form of page rank using popularity scores dependent on a
community rating can be used to improve precision.
This is similar to the statsrank method cite:nemaConsensusbasedRankingWikipedia2017a
**** [#B] Linear Algebra behind Google cite:bryan250000002006 :insight:
A discussion on the algebra behind the pagerank method.
*** Wikipedia
**** [#A] Network analysis of user generated content quality in Wikipedia  cite:ingawaleNetworkAnalysisUser2013a

Is there a relationship between content quality and the structure of connections? Can high quality Wikipedia pages be used as a benchmark for the structure of connections.

The network structure of interactions between articles plays an important role in the emergence of quality.

High quality articles clusture in hubs.

**** [#B] Using Wikipedia to alleviate data sparsity issues in Recommender Systems cite:loizouUsingWikipediaAlleviate2010a
For Recommender systems with limited access to data, Wikipedia can be used as an analogue with respect to connections to significantly improve performance.
*** Page Rank
**** [#A] A New Extrap method for PageRank computations cite:tanNewExtrapolationMethod2017a :performance:

A new algorithm can be used to improve the convergence rate of the power rank method, compared to the /power method/ when the smoothing parameter $\alpha$ is near 0

**** [#A] Page Rank Revisited cite:brinkmeierPageRankRevisited2006a :insight:
The Page Rank method can be expressed as a power series and an algorithm for calculating the page rank can be derived, this corresponds to the /power method/ but offers insights into the mechanisms of the method.

A slightly faster algorithm is suggested at \textsection 6.3.

This is quite interesting because expressing the power walk method as a power series may offer insights with respect to the convergence and stability of the algorithm
**** [#A] Ranking Nodes in Networks cite:berkhoutRankingNodesGeneral2018a :modification:
The choice of damping factor of Googles page rank might have a large impact on the values given to vertices.

This suggests an approach that uses structural network dynatims to provide an appropriate score distribution.

The method implemented is not something I have come yet to understand, but it could be very interesting to see:

- how it relates to the power walk method
- whether or not it could offer insightts into the convergence and stability of the power walk method
- Whether or not the method would be compatible with negatively weighted edges.

**** [#A] Reordering for the pagerank cite:langvilleReorderingPageRankProblem2006 :performance:
Reordering the pagerank problem and taking advantage of the fact that it is sparse can allow for an improved algorithm that can potentially improve performance or at worst offer no compromise in performance.
**** [#A] Consensus based raking of Wikipedia cite:nemaConsensusbasedRankingWikipedia2017a :modification:
Google's page rank method can be improved by replacing the background probability of $\frac{1}{n}$ with statistics of usage, this is referred to as the StatsRank, this can be aggregated with user opinion to give the ConsensusRank

A limitation of this approach is that usage stats are only really available, in a neutral fashion for wikis, so too bad.

**** [#A] Page rank as a function of the damping factor cite:boldiPageRankFunctionDamping2005 :insight:

Demonstrates the behaviour of page rank for varying values of \alpha.

Values nearer to 1 do not give a more meaningful ranking.

Using iteration i.e. (the power rankmethod) gives the same exact result as the power series at the same step, similar to what was shown by brinkmeier cite:brinkmeierPageRankRevisited2006a

This could be useful in developing analytical methods to solve the pagerank problem.
**** [#B] Modified Page Rank Algorithm for Biology cite:zhangModifiedPageRankAlgorithm2018 :modification:

The page rank method can be used for modelling gene expression.

**** [#B] Small World for Random Surfers cite:mehrabianItSmallWorld2016 :insight:
Graphs can be generated in order to model real world networks, these models can use the degree or  page rank of a given vertex as a parameter to create the next vertex in generating the graph.

This paper discusses upper and lower bounds for the diameter of a graph generated using random-surfer web-graph model.
**** [#B] Centrality ranking in Multiplex Networks cite:dingCentralityRankingMultiplex2018 :insight:

A technique to measure node centrality for a multi-dimensional graph.

**** [#B] Google's Page Rank :insight:
A Discussion of the Math behind googles page rank

**** [#B] Damping factor in Google Page Ranking cite:fuDampingFactorGoogle2006 :modification:
The damping factor is critical in changing a website's ranking in a search, this
modified algorithm, based on input-output ratio is proposed to substitute for
the damping factor.

It would be interesting to determine whether or not this type of a substitution could improve the performance of the /power walk/ method and what implications it would have on the method parameters and resulting convergence and stability.

**** [#C] Tang Two-hop walks indicate PageRank order cite:tangTwohopWalksIndicate2019

- I could not make out what the this one was about

**** [#C] Inside PageRank cite:bianchiniPageRank2005 :general:

This is a discussion on the stability, complexity and critical role of parameters involved in the computation.

- The page rank method will always converge for the random surfer eqref:eq:random-surfer provided that $\alpha < 1$ [[cite:bianchiniPageRank2005][\textsection 2.2]]

**** [#C] survey of eigenvectors for web info cite:langvilleSurveyEigenvectorMethods2005 :general:
Many methods for web information retrival involve eigen vectors.

PageRank is impervious to spamming.
**** [#C] PageRank of Integers :insight:
Page rank can be used in pure mathematics.
*** SEO
**** [#A] Adaptive Methods for computation of page rank cite:kamvarAdaptiveMethodsComputation2004b :discoverability:
Given a graph, how can we optimise the discoverability of a node by introducing a couple of edges. A node is considered as discoverable if it:

1. Has a high page rank value
2. The number of steps to reach that vertex from another vertex is low.

**** [#B] Maximizing Page Rank :discoverability:insight:
How can a domain be modified to improve it's page rank?

Provides an optimal linkage strategy

**** [#B] What is a tall poppy among web pages cite:WhatTallPoppy1998 :discoverability:
With a training set of collected pages from typical queries a decision tree
based machine learning algorithm is used to model a decision tree for a variety
of search engines.

Not totally relevant but a very interesting project and approach.
**** [#C] Analysing google through SEO Data cite:AnalysingGoogleRankings
Page Rank is an important feature of Search Engine Optimisation
**** [#C] impact of webpage content characteristics on webpage visibility cite:zhangImpactWebpageContent2005 :discoverability:
Webpage visibility can be improved by increasing the frequency of keywords

* Literature Review
The proposed research (see section [[#research-question]]) relates broadly to the /PageRank/ method, Random-Surfer model, sentiment
analysis and graph centrality, for which material is quite abundant, although much
of the literature is concerned with either:

1. The original /PageRank/ method developed by Page and Brin,
cite:larrypageAnatomyLargescaleHypertextual1998 OR
2. Modifying the pagerank method to improve upon:
  + Precision and accuracy
  + Performance with respect to:
    - Rate of convergence in terms of iterations and time
    - Stability of any given solution

Although either of these points are not a direct analogue for the proposed
research which relates in itself to a modified /PageRank/ algorithm, much of the
work will be very similar in approach hopefully offer and much insight upon
closer inspection.

** Literature Referred to in Primary Resource
This research is focused primarily on the /Power Walk/ method or approach to the
PageRank algorithm proposed by Park and Simoff in a 2013 conference paper,
cite:parkPowerWalkProceedings2013 this paper contained some discussion of
relevant research.


*** Stability and Convergence
Haveliwala and Kamvar cite:haveliwalaSecondEigenvalueGoogle2003 proved that the $\lambda_{2}$ (see eqref:eq:eigen-set)

research releating to the second eigenvalue of the /PageRank/ probability transition matrix
** Skimming and summary
*** From Paper
**** TODO [#A] Stable Algorithms for Link Analysis cite:ngStableAlgorithmsLink2001 :modification:insight:eigenvalue:
Investigates under what situations the pagerank of a matrix is resistant to perturbations of a graph, finding essentially that distance of $\lambda_{2}$ from 1 is important.

A new algorithm is suggested
**** TODO [#A] The second EigenValue of the Google Matrix cite:haveliwalaSecondEigenvalueGoogle2003,zhaoOptimizingNodeDiscovery2019 :eigenvalue:
Determine analytically the modulus of the second EigenValue for the /PageRank/ method.

provides that $\lambda_{2} \leq \alpha$ and if there are 2 or more irreducible subgraphs $\lambda_{2}=\alpha$.

This important for the rate of convergence of the algorithm.

**** TODO [#B] Community Based popularity cite:parkMiningWebMultiresolution :modification:
A more general form of page rank using popularity scores dependent on a
community rating can be used to improve precision.
This is similar to the statsrank method cite:nemaConsensusbasedRankingWikipedia2017a
**** TODO [#B] Linear Algebra behind Google cite:bryan250000002006 :insight:
A discussion on the algebra behind the pagerank method.
*** TODO Wikipedia
**** TODO [#A] Network analysis of user generated content quality in Wikipedia  cite:ingawaleNetworkAnalysisUser2013a

Is there a relationship between content quality and the structure of connections? Can high quality Wikipedia pages be used as a benchmark for the structure of connections.

The network structure of interactions between articles plays an important role in the emergence of quality.

High quality articles clusture in hubs.

**** TODO [#B] Using Wikipedia to alleviate data sparsity issues in Recommender Systems cite:loizouUsingWikipediaAlleviate2010a
For Recommender systems with limited access to data, Wikipedia can be used as an analogue with respect to connections to significantly improve performance.
*** TODO Page Rank
**** TODO [#A] A New Extrap method for PageRank computations cite:tanNewExtrapolationMethod2017a :performance:

A new algorithm can be used to improve the convergence rate of the power rank method, compared to the /power method/ when the smoothing constant $\alpha$ is near 0

**** TODO [#A] Page Rank Revisited cite:brinkmeierPageRankRevisited2006a :insight:
The Page Rank method can be expressed as a power series and an algorithm for calculating the page rank can be derived, this corresponds to the /power method/ but offers insights into the mechanisms of the method.

A slightly faster algorithm is suggested at \textsection 6.3.

This is quite interesting because expressing the power walk method as a power series may offer insights with respect to the convergence and stability of the algorithm
**** TODO [#A] Ranking Nodes in Networks cite:berkhoutRankingNodesGeneral2018a :modification:
The choice of damping factor of Googles page rank might have a large impact on the values given to vertices.

This suggests an approach that uses structural network dynatims to provide an appropriate score distribution.

The method implemented is not something I have come yet to understand, but it could be very interesting to see:

- how it relates to the power walk method
- whether or not it could offer insightts into the convergence and stability of the power walk method
- Whether or not the method would be compatible with negatively weighted edges.

**** TODO [#A] Reordering for the pagerank cite:langvilleReorderingPageRankProblem2006 :performance:
Reordering the pagerank problem and taking advantage of the fact that it is sparse can allow for an improved algorithm that can potentially improve performance or at worst offer no compromise in performance.
**** TODO [#A] Consensus based raking of Wikipedia cite:nemaConsensusbasedRankingWikipedia2017a :modification:
Google's page rank method can be improved by replacing the background probability of $\frac{1}{n}$ with statistics of usage, this is referred to as the StatsRank, this can be aggregated with user opinion to give the ConsensusRank

A limitation of this approach is that usage stats are only really available, in a neutral fashion for wikis, so too bad.

**** TODO [#A] Page rank as a function of the damping factor cite:boldiPageRankFunctionDamping2005 :insight:

Demonstrates the behaviour of page rank for varying values of \alpha.

Values nearer to 1 do not give a more meaningful ranking.

Using iteration i.e. (the power rankmethod) gives the same exact result as the power series at the same step, similar to what was shown by brinkmeier cite:brinkmeierPageRankRevisited2006a

This could be useful in developing analytical methods to solve the pagerank problem.
**** TODO [#B] Modified Page Rank Algorithm for Biology cite:zhangModifiedPageRankAlgorithm2018 :modification:

The page rank method can be used for modelling gene expression.

**** TODO [#B] Small World for Random Surfers cite:mehrabianItSmallWorld2016 :insight:
Graphs can be generated in order to model real world networks, these models can use the degree or  page rank of a given vertex as a parameter to create the next vertex in generating the graph.

This paper discusses upper and lower bounds for the diameter of a graph generated using random-surfer web-graph model.
**** TODO [#B] Centrality ranking in Multiplex Networks cite:dingCentralityRankingMultiplex2018 :insight:

A technique to measure node centrality for a multi-dimensional graph.

**** TODO [#B] Google's Page Rank :insight:
A Discussion of the Math behind googles page rank

**** TODO [#B] Damping factor in Google Page Ranking cite:fuDampingFactorGoogle2006 :modification:
The damping factor is critical in changing a website's ranking in a search, this
modified algorithm, based on input-output ratio is proposed to substitute for
the damping factor.

It would be interesting to determine whether or not this type of a substitution could improve the performance of the /power walk/ method and what implications it would have on the method parameters and resulting convergence and stability.

**** TODO [#C] Tang Two-hop walks indicate PageRank order cite:tangTwohopWalksIndicate2019

- I could not make out what the this one was about

**** TODO [#C] Inside PageRank cite:bianchiniPageRank2005 :general:

This is a discussion on the stability, complexity and critical role of parameters involved in the computation.

- The page rank method will always converge for the random surfer eqref:eq:random-surfer provided that $\alpha < 1$ [[cite:bianchiniPageRank2005][\textsection 2.2]]

**** TODO [#C] survey of eigenvectors for web info cite:langvilleSurveyEigenvectorMethods2005 :general:
Many methods for web information retrival involve eigen vectors.

PageRank is impervious to spamming.
**** TODO [#C] PageRank of Integers :insight:
Page rank can be used in pure mathematics.
*** TODO SEO
**** TODO [#A] Adaptive Methods for computation of page rank cite:kamvarAdaptiveMethodsComputation2004b :discoverability:
Given a graph, how can we optimise the discoverability of a node by introducing a couple of edges. A node is considered as discoverable if it:

1. Has a high page rank value
2. The number of steps to reach that vertex from another vertex is low.

**** TODO [#B] Maximizing Page Rank :discoverability:insight:
How can a domain be modified to improve it's page rank?

Provides an optimal linkage strategy

**** TODO [#B] What is a tall poppy among web pages cite:WhatTallPoppy1998 :discoverability:
With a training set of collected pages from typical queries a decision tree
based machine learning algorithm is used to model a decision tree for a variety
of search engines.

Not totally relevant but a very interesting project and approach.
**** TODO [#C] Analysing google through SEO Data cite:AnalysingGoogleRankings
Page Rank is an important feature of Search Engine Optimisation
**** TODO [#C] impact of webpage content characteristics on webpage visibility cite:zhangImpactWebpageContent2005 :discoverability:
Webpage visibility can be improved by increasing the frequency of keywords

* Footnotes

[fn:dom] Dominant in this case refers to the the largest $\mid \lambda_{k} \mid$
